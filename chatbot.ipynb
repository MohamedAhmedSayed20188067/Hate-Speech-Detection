{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T01:15:27.192256100Z",
     "start_time": "2023-08-06T01:15:26.711744200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_words)\n",
    "def remove_punctuation_numbers_stopwords(text):\n",
    "     # Replace numbers and punctuations with spaces\n",
    "    cleaned_text = re.sub(r'[0-9]+', ' ', text)\n",
    "    cleaned_text = re.sub(r'[{}]'.format(re.escape(string.punctuation)), ' ', cleaned_text)\n",
    "    # Remove extra spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    # Remove single-character words\n",
    "    cleaned_text = ' '.join(word for word in cleaned_text.split() if len(word) > 1)\n",
    "     # Remove stopwords\n",
    "    cleaned_text = ' '.join(word for word in cleaned_text.split() if word not in nltk.corpus.stopwords.words('english'))\n",
    "    return cleaned_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T01:15:27.268044800Z",
     "start_time": "2023-08-06T01:15:27.258181500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at .\\hateSpeachModel were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at .\\hateSpeachModel.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained(r\".\\hateSpeachModel\")\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained(r\".\\hateSpeachModel\")\n",
    "\n",
    "# Function to get model predictions\n",
    "def get_prediction(input_text):\n",
    "    input_text = lemmatize_text(input_text)\n",
    "    input_text = remove_punctuation_numbers_stopwords(input_text)\n",
    "    inputs = loaded_tokenizer(input_text, return_tensors=\"tf\")\n",
    "    predictions = loaded_model(inputs)\n",
    "    categories = {1: 'hate', 0: 'normal'}\n",
    "    return categories[np.argmax(predictions.logits)]\n",
    "\n",
    "# Function to handle user input and display responses\n",
    "def send_message():\n",
    "    user_input = entry.get()\n",
    "    if user_input.strip() == \"\":\n",
    "        return\n",
    "\n",
    "    response = get_prediction(user_input)\n",
    "    chat_box.config(state=tk.NORMAL)\n",
    "    chat_box.insert(tk.END, f\"User: {'*'*len(user_input)}\\n\", \"user_message\")\n",
    "    chat_box.insert(tk.END, f\"ChatBot: {response}\\n\", \"bot_message\")\n",
    "    chat_box.config(state=tk.DISABLED)\n",
    "    entry.delete(0, tk.END)\n",
    "\n",
    "# Function to display a welcome message\n",
    "def show_welcome_message():\n",
    "    chat_box.config(state=tk.NORMAL)\n",
    "    chat_box.insert(tk.END, \"ChatBot: Hi! I'm a simple chatbot. Type your message below classify Either hate or normal\\n\", \"bot_message\")\n",
    "    chat_box.config(state=tk.DISABLED)\n",
    "\n",
    "# Set up the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"ChatBot\")\n",
    "\n",
    "chat_box = tk.Text(root, width=50, height=15, state=tk.DISABLED)\n",
    "scrollbar = tk.Scrollbar(root, command=chat_box.yview)\n",
    "chat_box.config(yscrollcommand=scrollbar.set)\n",
    "chat_box.tag_configure(\"bot_message\", foreground=\"blue\")\n",
    "chat_box.tag_configure(\"user_message\", foreground=\"green\")\n",
    "\n",
    "entry = tk.Entry(root, width=40,show='*')\n",
    "send_button = tk.Button(root, text=\"Send\", command=send_message)\n",
    "exit_button = tk.Button(root, text=\"Exit\", command=root.destroy)\n",
    "\n",
    "chat_box.grid(row=0, column=0, padx=10, pady=10, columnspan=2 )\n",
    "scrollbar.grid(row=0, column=2, sticky=\"ns\")\n",
    "entry.grid(row=1, column=0, padx=10, pady=5)\n",
    "send_button.grid(row=1, column=1, padx=5, pady=5)\n",
    "exit_button.grid(row=2, column=0, columnspan=2, pady=10)\n",
    "\n",
    "\n",
    "# Display the welcome message when the chatbot starts\n",
    "show_welcome_message()\n",
    "root.mainloop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T01:15:46.565600400Z",
     "start_time": "2023-08-06T01:15:27.722391700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-06T01:15:46.565600400Z",
     "start_time": "2023-08-06T01:15:46.551208500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
